<!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8">

    <title>Getting Started with Web Audio</title>

    <meta name="description" content="Web Audio API - Getting Started">
    <meta name="author" content="Josh Durham">

    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

    <link rel="stylesheet" href="css/reveal.css">
    <link rel="stylesheet" href="css/theme/black.css" id="theme">

    <!-- Code syntax highlighting -->
    <link rel="stylesheet" href="lib/css/zenburn.css">

    <!-- Printing and PDF exports -->
    <script>
        var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
    </script>
    <link type="text/css" rel="stylesheet" href="style.css">
    <!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
</head>

<body>

    <div class="reveal">

        <!-- Any section element inside of this container is displayed as a slide -->
        <div class="slides">

            <section class="slide">
                <iframe data-src="iframes/title.html" frameborder="0"></iframe>
                <div class="page-cover">
                    <h1 class="cover-title">An Introduction to Web Audio</h1>
                    <h1 class="cover-title"><small>and other things</small></h1>
                    <p>
                        <small>Josh Durham</small>
                    </p>
                </div>
            </section>

            <section>
                <h2>Aim</h2>
                <ul>
                    <li>
                        Cover the basic concpets you will need to get started on your Web Audio API journey.
                    </li>
                    <li>Demonstate how easy it is to get started with Web Audio API and how powerful it is.</li>
                </ul>
            </section>

            <!-- Example of nested vertical slides -->
            <section>
                <section>
                    <h2>So what is Web Audio API?</h2>
                    <ul>
                        <li>The Web Audio API provides a powerful and versatile system for controlling audio on the Web,
                           allowing developers to choose audio sources, add effects to audio, create audio visualizations, 
                           apply spatial effects (such as panning) and much more.</li>
                        <li>The Web Audio API involves handling audio operations inside an audio context, 
                          and has been designed to allow modular routing via audio nodes and an audio routing graph</li>
                        <li>You don't have to know what a fast Fourier Transform is or really any maths</li>
                    </ul>
                </section>
                <section>
                    <div class='slide'>
                        <h3>Browser Support</h3>
                        <img src="images/support.png" style="height:500px; width:1200px" alt="">
                    </div>
                </section>
            </section>

            <section>
                <h2>The Audio Pipeline Overview</h2>
                <ul>
                  <li>Create audio context</li>
                  <li>Inside the context, create sources — such as <code>&lt;audio&gt;</code>, oscillator, stream</li>
                  <li>Create effects nodes, such as reverb, biquad filter, panner, compressor</li>
                  <li>Choose final destination of audio, for example your system speakers</li>
                  <li>Connect the sources up to the effects, and the effects to the destination.</li>
                </ul>
                <br/>
                <img src="images/typical_workflow.png" />
                <p><a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API">Details</a></p>
            </section>

            <section>
                <section>
                    <h2>Web Audio API Interfaces</h2>
                    <p>There are a number of interfaces and associated events, which are split up into nine categories of functionality.</p>
                </section>
                <section>
                    <h2>General audio graph definition</h2>
                    <P>General containers and definitions that shape audio graphs in Web Audio API usage</p>
                    <UL>
                        <LI><a href="https://developer.mozilla.org/en-US/docs/Web/API/AudioContext">AudioContext</a></LI>
                        <LI><a href="https://developer.mozilla.org/en-US/docs/Web/API/AudioNode">AudioNode</a></LI>
                        <LI><a href="https://developer.mozilla.org/en-US/docs/Web/API/AudioParam">AudioParam</a></LI>

                    </UL>
                </section>
                <section>
                    <h2>Defining audio sources</h2>
                    <P>Interfaces that define audio sources for use in the Web Audio API</p>
                    <UL>
                        <LI><a href="https://developer.mozilla.org/en-US/docs/Web/API/OscillatorNode">OscillatorNode</a></LI>
                        <LI><a href="https://developer.mozilla.org/en-US/docs/Web/API/AudioBuffer">AudioBuffer</a></LI>
                        <LI><a href="https://developer.mozilla.org/en-US/docs/Web/API/MediaStreamAudioSourceNode">MediaStreamAudioSourceNode</a></LI>

                    </UL>
                </section>
                <section>
                    <h2>Defining audio effects filters</h2>
                    <P>Interfaces for defining effects that you want to apply to your audio sources</p>
                    <UL>
                        <LI><a href="https://developer.mozilla.org/en-US/docs/Web/API/BiquadFilterNode">BiquadFilterNode</a></LI>
                        <LI><a href="https://developer.mozilla.org/en-US/docs/Web/API/ConvolverNode">ConvolverNode</a></LI>
                        <LI><a href="https://developer.mozilla.org/en-US/docs/Web/API/DelayNode">DelayNode</a></LI>

                    </UL>
                </section>
                <section>
                    <h2>Defining audio destinations</h2>
                    <P>Once you are done processing your audio, these interfaces define where to output it</p>
                    <UL>
                        <LI><a href="https://developer.mozilla.org/en-US/docs/Web/API/AudioDestinationNode">AudioDestinationNode</a></LI>
                        <LI><a href="https://developer.mozilla.org/en-US/docs/Web/API/MediaStreamAudioDestinationNode">MediaStreamAudioDestinationNode</a></LI>
                    </UL>
                </section>
                <section>
                    <h2>Data analysis and visualization</h2>
                    <P>If you want to extract time, frequency, and other data from your audio, the AnalyserNode is what you need</p>
                    <UL>
                        <LI><a href="https://developer.mozilla.org/en-US/docs/Web/API/AnalyserNode">AnalyserNode</a></LI>
                    </UL>
                </section>
                <section>
                    <h2>Splitting and merging audio channels</h2>
                    <P>To split and merge audio channels, you'll use these interfaces</p>
                    <UL>
                        <LI><a href="https://developer.mozilla.org/en-US/docs/Web/API/ChannelSplitterNode">ChannelSplitterNode</a></LI>
                        <LI><a href="https://developer.mozilla.org/en-US/docs/Web/API/ChannelMergerNode">ChannelMergerNode</a></LI>
                    </UL>
                </section>
                <section>
                    <h2>Audio spatialization</h2>
                    <P>These interfaces allow you to add audio spatialization panning effects to your audio sources</p>
                    <UL>
                        <LI><a href="https://developer.mozilla.org/en-US/docs/Web/API/AudioListener">AudioListener</a></LI>
                        <LI><a href="https://developer.mozilla.org/en-US/docs/Web/API/PannerNode">PannerNode</a></LI>
                    </UL>
                </section>
                <section>
                    <h2>Audio processing in JavaScript</h2>
                    <P>You can write JavaScript code to process audio data manually.</p>
                </section>
                <section>
                    <h2>Offline/background audio processing</h2>
                    <P>It is possible to process/render an audio graph very quickly in the background — rendering it to an AudioBuffer rather than to the device's speakers</p>
                </section>
            </section>
            <section>
                <h2>Putting the Pieces Together</h2>
                <p><a href="https://webaudioplayground.appspot.com/">Web Audio Playground</a></p>
                
            </section>

            <section>
                <h2>Looking at Basic Examples</h2>
                <p><a href="https://codepen.io/jpdurham/pen/dRWzJj">Oscillators</a></p>
                <p><a href="https://codepen.io/jpdurham/pen/EXmZYq/">Mic Input</a></p>
            </section>

            <section>
              <section>
                <h2>So What About Guitar Pedals?</h2>
                <p><a href="https://codepen.io/jpdurham/pen/yXboqV">Distortion</a></p>

              </section>
              <section>
                <h2>Hasn't Someone Already Done This?</h2>
                <p>Yes, <a href="https://pedals.io/">pedals.io</a> has!</a>
              </section>
            </section>

            <section>
              <h2>Can I Use This in Game Development!?</h2>
              <p><a href="https://googlechrome.github.io/web-audio-samples/samples/audio/box2d-js/box2d-audio.html">Definitely!</a></p>
              <p><a href="http://srchea.com/experimenting-with-web-audio-api-three-js-webgl">More defintely!!</a></p>
              <p><a href="http://blog.sklambert.com/html5-canvas-game-html5-audio-and-finishing-touches/">Most definitely!!!</a></p>
              <br/>
              <p><a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Web_audio_spatialization_basics">Notes on Spacialization</a></p>
            </section>

            <section>
              <h2>Some other neat demos</h2>
              <ul>
                <li><a href="http://alteredqualia.com/three/examples/webgl_city.html">WebGL City</a></li>
                <li><a href="https://mdn.github.io/webaudio-examples/panner-node/">Panner</a></li>
                <li><a href="http://webaudioapi.com/samples/">Basic Examples</a></li>
                <li><a href="https://googlechrome.github.io/web-audio-samples/samples/audio/">Advanced demos</a></li>
                <li><a href="https://alemangui.github.io/pizzicato/">Pizzicato.js</a></li>
              </ul>
            </section>
            <!-- Questions? -->
            <section>
                <h2>Questions or Comments?</h2>
                <br/>
                <br/>
                <p>View the slides at <a href="https://jpdurham.github.io/An-Introduction-to-Web-Audio/">https://jpdurham.github.io/An-Introduction-to-Web-Audio/</a></p>
                <p>Created by Josh Durham</p>
            </section>

        </div>

    </div>

    <script src="lib/js/head.min.js"></script>
    <script src="js/reveal.js"></script>

    <script>
        // Full list of configuration options available at:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: true,
                
                width: '100%',
                height: '100%',

				transition: 'slide', // none/fade/slide/convex/concave/zoom

				// Optional reveal.js plugins
				dependencies: [
					{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true, condition: function() { return !!document.querySelector( 'pre code' ); }, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/zoom-js/zoom.js', async: true },
					{ src: 'plugin/notes/notes.js', async: true }
				]
			});
    </script>

    <script>
        function getCurrentFrame() {
            // debugger
            var elems = document.getElementsByClassName("slide present");
            if (elems.length > 0) {
                var iframes = elems[0].getElementsByTagName("iframe")
                if (iframes.length > 0) {
                    return iframes[0].contentWindow
                }
            } 
            return null
        }
            var frame = null            
            Reveal.addEventListener( 'slidechanged', function( event ) {
                // event.previousSlide, event.currentSlide, event.indexh, event.indexv
                frame = getCurrentFrame()
            } );
            
            Reveal.addEventListener( 'fragmentshown', function( event ) {
                // debugger
                if (!frame) {
                    frame = getCurrentFrame()
                }
                if (frame) {
                    var args = [parseInt(event.fragments[0].getAttribute("data-fragment-index")) + 1]
                    var director = {args: args}
                    var data = {director: director}
                    frame.postMessage(data, "*")
                }
                // event.previousSlide, event.currentSlide, event.indexh, event.indexv
            } );
            
            Reveal.addEventListener( 'fragmenthidden', function( event ) {
                // debugger
                if (!frame) {
                    frame = getCurrentFrame()
                }
                if (frame) {
                    var args = [parseInt(event.fragments[0].getAttribute("data-fragment-index"))]
                    var director = {args: args}
                    var data = {director: director}
                    frame.postMessage(data, "*")
                }
                // event.previousSlide, event.currentSlide, event.indexh, event.indexv
            } );
    </script>

    <style type="text/css">
        .fragment.visible.visible:not(.current-fragment) {
            display: none;
            height: 0px;
            line-height: 0px;
            font-size: 0px;
        }
        
        iframe {
            height: 100%;
            width: 100%;
        }
        
        section {
            height: 50%;
        }
        
        .reveal .slides {
            height: 100%;
            top: 0;
            margin-top: 0;
        }
        
        .reveal .slides>section {
            min-height: 90%;
        }
        
        .reveal .slides>section>section {
            min-height: 100%;
        }
        
        .reveal pre {
            margin-top: 0
        }
    </style>
    
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-48759750-3', 'auto');
    ga('send', 'pageview');
  </script>

</body>

</html>
